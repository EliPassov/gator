{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time, sleep\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.models.resnet import resnet50\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'analysis':\n",
    "    os.chdir('..')\n",
    "from models.gates_mapper import GatesModulesMapper, NaiveSequentialGatesModulesMapper, ResNetGatesModulesMapper\n",
    "from models.wrapped_gated_models import ResNet18_gating, ResNet34_gating, ResNet50_gating, custom_resnet_from_gated_net\n",
    "from models.gate_wrapped_module import compute_flop_cost_change, create_conv_channels_dict, create_edge_to_channels_map, dot_string_to_tree_dict\n",
    "from models.custom_resnet import filter_mapping_from_default_resnet, custom_resnet_50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_net(net, run_times=1, measurements=100, lower_limit=0, upper_limit=500000, sleep_seconds=0):\n",
    "    net.eval()\n",
    "    total_times=[]\n",
    "    for _ in range(run_times):\n",
    "        sample = torch.rand((8,3,224,224)).cuda(1)\n",
    "        times = []\n",
    "        for i in range(measurements):\n",
    "            t = time()\n",
    "            res = net(sample)\n",
    "            aa = res[-1,-1].item()\n",
    "            times.append(time()-t)\n",
    "        times = np.array(times)\n",
    "        times = 1000 * times\n",
    "#         times.sort()\n",
    "#         times = times[lower_limit:upper_limit]\n",
    "        total_times.append(times)\n",
    "#         sleep(1.0)\n",
    "    net.train()\n",
    "\n",
    "    total_times=np.array(total_times)\n",
    "    sleep(sleep_seconds)\n",
    "    return(total_times.min())\n",
    "    \n",
    "#     remove_range=[]\n",
    "#     std = np.median(total_times.std(1))\n",
    "#     for i in range(len(total_times)):\n",
    "#         if total_times[i].mean() - np.median(total_times) > std:\n",
    "#             remove_range.append(i)\n",
    "    \n",
    "#     total_times = np.delete(total_times, remove_range, axis=0)\n",
    "\n",
    "#     print('25-75 mean, std, min, max (ms) \\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}'.format(times.mean(), times.std(), times.min(), times.max()))\n",
    "\n",
    "#     return total_times\n",
    "\n",
    "#     return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.162063598632812\n"
     ]
    }
   ],
   "source": [
    "resnet_original = resnet50(True)\n",
    "resnet_original = resnet_original.cuda(1)\n",
    "print(time_net(resnet_original))\n",
    "# for i in range(10):\n",
    "#     times=time_net(resnet_original)\n",
    "#     print(np.array(times).min())\n",
    "#     sleep(20)\n",
    "# for i in range(10):\n",
    "#     times.append(time_net(resnet_original))\n",
    "#     sleep(1.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/victoria/d/projects/gator/models/wrapped_gated_models.py:36: UserWarning: created gating module with 0 weight, make sure you are not training it\n",
      "  warnings.warn(\"created gating module with 0 weight, make sure you are not training it\")\n"
     ]
    }
   ],
   "source": [
    "# Resnet50\n",
    "net_name = 'ResNet50_gating'\n",
    "weight_path = '/media/victoria/d/Training/Eli/resnet50_pre_0_995_w_0_25_gm_0_2_w_0_5_w_1_w_2/net_e_140'\n",
    "\n",
    "no_last_conv=False\n",
    "\n",
    "net, aaa, _ = globals()[net_name](1000)\n",
    "state_dict = torch.load(weight_path)['state_dict']\n",
    "state_dict = {k[7:]: v for k,v in state_dict.items()}\n",
    "net.load_state_dict(state_dict)\n",
    "mapper = ResNetGatesModulesMapper(net.net, no_last_conv, map_for_replacement=True)\n",
    "custom_net = custom_resnet_from_gated_net(net_name, weight_path).cuda(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flop comperssion ratio: 1.46 original cost 76848.00 new cost 52639.88\n",
      "memory comperssion ratio: 1.11 original cost 23454912.00 new cost 21189636.00\n"
     ]
    }
   ],
   "source": [
    "for factor in ['flop', 'memory']:\n",
    "    original_cost, new_cost = compute_flop_cost_change(net, mapper, factor_type= factor + \"_factor\")\n",
    "    print(\"{} comperssion ratio: {:.2f} original cost {:.2f} new cost {:.2f}\".format(factor, original_cost/new_cost, original_cost, new_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flop comperssion ratio: 1.37 original cost 76848.00 new cost 56277.48\n",
      "memory comperssion ratio: 1.06 original cost 23454912.00 new cost 22124172.00\n"
     ]
    }
   ],
   "source": [
    "for factor in ['flop', 'memory']:\n",
    "    original_cost, new_cost = compute_flop_cost_change(net, mapper, factor_type= factor + \"_factor\")\n",
    "    print(\"{} comperssion ratio: {:.2f} original cost {:.2f} new cost {:.2f}\".format(factor, original_cost/new_cost, original_cost, new_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flop comperssion ratio: 2.00 original cost 76848.00 new cost 38474.25\n",
      "memory comperssion ratio: 1.26 original cost 23454912.00 new cost 18619922.00\n"
     ]
    }
   ],
   "source": [
    "for factor in ['flop', 'memory']:\n",
    "    original_cost, new_cost = compute_flop_cost_change(net, mapper, factor_type= factor + \"_factor\")\n",
    "    print(\"{} comperssion ratio: {:.2f} original cost {:.2f} new cost {:.2f}\".format(factor, original_cost/new_cost, original_cost, new_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flop comperssion ratio: 1.93 original cost 76848.00 new cost 39736.22\n",
      "memory comperssion ratio: 1.24 original cost 23454912.00 new cost 18852860.00\n"
     ]
    }
   ],
   "source": [
    "for factor in ['flop', 'memory']:\n",
    "    original_cost, new_cost = compute_flop_cost_change(net, mapper, factor_type= factor + \"_factor\")\n",
    "    print(\"{} comperssion ratio: {:.2f} original cost {:.2f} new cost {:.2f}\".format(factor, original_cost/new_cost, original_cost, new_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flop comperssion ratio: 2.68 original cost 76848.00 new cost 28684.06\n",
      "memory comperssion ratio: 1.52 original cost 23454912.00 new cost 15446608.00\n"
     ]
    }
   ],
   "source": [
    "for factor in ['flop', 'memory']:\n",
    "    original_cost, new_cost = compute_flop_cost_change(net, mapper, factor_type= factor + \"_factor\")\n",
    "    print(\"{} comperssion ratio: {:.2f} original cost {:.2f} new cost {:.2f}\".format(factor, original_cost/new_cost, original_cost, new_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flop comperssion ratio: 4.28 original cost 76848.00 new cost 17971.34\n",
      "memory comperssion ratio: 2.50 original cost 23454912.00 new cost 9397143.00\n"
     ]
    }
   ],
   "source": [
    "for factor in ['flop', 'memory']:\n",
    "    original_cost, new_cost = compute_flop_cost_change(net, mapper, factor_type= factor + \"_factor\")\n",
    "    print(\"{} comperssion ratio: {:.2f} original cost {:.2f} new cost {:.2f}\".format(factor, original_cost/new_cost, original_cost, new_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flop comperssion ratio: 7.21 original cost 76848.00 new cost 10658.53\n",
      "memory comperssion ratio: 4.49 original cost 23454912.00 new cost 5228501.00\n"
     ]
    }
   ],
   "source": [
    "for factor in ['flop', 'memory']:\n",
    "    original_cost, new_cost = compute_flop_cost_change(net, mapper, factor_type= factor + \"_factor\")\n",
    "    print(\"{} comperssion ratio: {:.2f} original cost {:.2f} new cost {:.2f}\".format(factor, original_cost/new_cost, original_cost, new_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.209177017211914"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_net(custom_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.297225952148438"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_net(custom_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.02447509765625"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_net(custom_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.547233581542969"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_net(custom_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.53531265258789"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_net(custom_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.979869842529297"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_net(custom_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.571292877197266"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_net(custom_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "for i in range(len(times)):\n",
    "    plt.plot(times[i], label=str(i))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(times)):\n",
    "    print(((times[i][1:]-times[i][:-1])<0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0, 100.0000,  14.1511\n",
      " 1,  97.6369,  13.3538\n",
      " 2,  98.3344,  13.6471\n",
      " 3,  97.8347,  13.5651\n",
      " 4,  97.8347,  13.6349\n",
      " 5,  97.8347,  13.5915\n",
      " 6,  97.8347,  13.6435\n",
      " 7,  97.8347,  13.6027\n",
      " 8,  94.3369,  12.4342\n",
      " 9,  98.1678,  13.4819\n",
      "10,  97.8347,  13.6530\n",
      "11,  97.8347,  13.6702\n",
      "12,  97.8347,  13.6149\n",
      "13,  97.8347,  13.6433\n",
      "14,  97.8347,  13.6054\n",
      "15,  97.8347,  13.6774\n",
      "16,  97.8347,  13.6030\n",
      "17,  92.3381,  12.6061\n",
      "18,  98.1678,  13.5615\n",
      "19,  97.8347,  13.6697\n",
      "20,  97.8347,  13.6843\n",
      "21,  97.8347,  13.6261\n",
      "22,  97.8347,  13.6459\n",
      "23,  97.8347,  13.6266\n",
      "24,  97.8347,  13.6690\n",
      "25,  97.8347,  13.6325\n",
      "26,  97.8347,  13.6769\n",
      "27,  97.8347,  13.6366\n",
      "28,  97.8347,  13.6580\n",
      "29,  97.8347,  13.5863\n",
      "30,  89.6731,  12.4362\n",
      "31,  98.1678,  13.4728\n",
      "32,  97.8347,  13.5407\n",
      "33,  97.8347,  13.5648\n",
      "34,  97.8347,  13.5281\n",
      "35,  97.8347,  13.5434\n",
      "36,  97.8347,  13.5252\n",
      "37,  95.3362,  13.0966\n",
      " 0, 100.0000,  13.7303\n",
      " 1,  97.6369,  13.3791\n",
      " 2,  98.3344,  13.6652\n",
      " 3,  97.8347,  13.5932\n",
      " 4,  97.8347,  13.6683\n",
      " 5,  97.8347,  13.6390\n",
      " 6,  97.8347,  13.6759\n",
      " 7,  97.8347,  13.6251\n",
      " 8,  94.3369,  12.4524\n",
      " 9,  98.1678,  13.4790\n",
      "10,  97.8347,  13.6786\n",
      "11,  97.8347,  13.6805\n",
      "12,  97.8347,  13.6542\n",
      "13,  97.8347,  13.6585\n",
      "14,  97.8347,  13.6423\n",
      "15,  97.8347,  13.6793\n",
      "16,  97.8347,  13.6223\n",
      "17,  92.3381,  12.5992\n",
      "18,  98.1678,  13.5472\n",
      "19,  97.8347,  13.7043\n",
      "20,  97.8347,  13.6542\n",
      "21,  97.8347,  13.6254\n",
      "22,  97.8347,  13.6471\n",
      "23,  97.8347,  13.6306\n",
      "24,  97.8347,  13.6602\n",
      "25,  97.8347,  13.6058\n",
      "26,  97.8347,  13.6728\n",
      "27,  97.8347,  13.6194\n",
      "28,  97.8347,  13.6969\n",
      "29,  97.8347,  13.6378\n",
      "30,  89.6731,  12.4607\n",
      "31,  98.1678,  13.4692\n",
      "32,  97.8347,  13.5686\n",
      "33,  97.8347,  13.5872\n",
      "34,  97.8347,  13.5114\n",
      "35,  97.8347,  13.6082\n",
      "36,  97.8347,  13.5148\n",
      "37,  95.3362,  13.0975\n",
      " 0, 100.0000,  13.7711\n",
      " 1,  97.6369,  13.3803\n",
      " 2,  98.3344,  13.6755\n",
      " 3,  97.8347,  13.6061\n",
      " 4,  97.8347,  13.6645\n",
      " 5,  97.8347,  13.6070\n",
      " 6,  97.8347,  13.6609\n",
      " 7,  97.8347,  13.6194\n",
      " 8,  94.3369,  12.4824\n",
      " 9,  98.1678,  13.5088\n",
      "10,  97.8347,  13.7045\n",
      "11,  97.8347,  13.6998\n",
      "12,  97.8347,  13.6392\n",
      "13,  97.8347,  13.6988\n",
      "14,  97.8347,  13.6242\n",
      "15,  97.8347,  13.6905\n",
      "16,  97.8347,  13.6263\n",
      "17,  92.3381,  12.6083\n",
      "18,  98.1678,  13.5596\n",
      "19,  97.8347,  13.6871\n",
      "20,  97.8347,  13.6857\n",
      "21,  97.8347,  13.6542\n",
      "22,  97.8347,  13.6716\n",
      "23,  97.8347,  13.6158\n",
      "24,  97.8347,  13.7002\n",
      "25,  97.8347,  13.6223\n",
      "26,  97.8347,  13.6855\n",
      "27,  97.8347,  13.6485\n",
      "28,  97.8347,  13.6840\n",
      "29,  97.8347,  13.6306\n",
      "30,  89.6731,  12.4786\n",
      "31,  98.1678,  13.4764\n",
      "32,  97.8347,  13.5446\n",
      "33,  97.8347,  13.5665\n",
      "34,  97.8347,  13.5322\n",
      "35,  97.8347,  13.5958\n",
      "36,  97.8347,  13.5307\n",
      "37,  95.3362,  13.0978\n",
      " 0, 100.0000,  13.7804\n",
      " 1,  97.6369,  13.3786\n",
      " 2,  98.3344,  13.7031\n",
      " 3,  97.8347,  13.6106\n",
      " 4,  97.8347,  13.6831\n",
      " 5,  97.8347,  13.6464\n",
      " 6,  97.8347,  13.6845\n",
      " 7,  97.8347,  13.6414\n",
      " 8,  94.3369,  12.4927\n",
      " 9,  98.1678,  13.5109\n",
      "10,  97.8347,  13.6924\n",
      "11,  97.8347,  13.6976\n",
      "12,  97.8347,  13.6402\n",
      "13,  97.8347,  13.6831\n",
      "14,  97.8347,  13.6359\n",
      "15,  97.8347,  13.6738\n",
      "16,  97.8347,  13.6817\n",
      "17,  92.3381,  12.5890\n",
      "18,  98.1678,  13.6054\n",
      "19,  97.8347,  13.6995\n",
      "20,  97.8347,  13.6890\n",
      "21,  97.8347,  13.6614\n",
      "22,  97.8347,  13.7050\n",
      "23,  97.8347,  13.6421\n",
      "24,  97.8347,  13.6771\n",
      "25,  97.8347,  13.6485\n",
      "26,  97.8347,  13.6631\n",
      "27,  97.8347,  13.6611\n",
      "28,  97.8347,  13.6893\n",
      "29,  97.8347,  13.6466\n",
      "30,  89.6731,  12.4567\n",
      "31,  98.1678,  13.5038\n",
      "32,  97.8347,  13.5736\n",
      "33,  97.8347,  13.6249\n",
      "34,  97.8347,  13.5460\n",
      "35,  97.8347,  13.5849\n",
      "36,  97.8347,  13.5562\n",
      "37,  95.3362,  13.1090\n",
      " 0, 100.0000,  13.7691\n",
      " 1,  97.6369,  13.3982\n",
      " 2,  98.3344,  13.6940\n",
      " 3,  97.8347,  13.6156\n",
      " 4,  97.8347,  13.7012\n",
      " 5,  97.8347,  13.6268\n",
      " 6,  97.8347,  13.6547\n",
      " 7,  97.8347,  13.6216\n",
      " 8,  94.3369,  12.4850\n",
      " 9,  98.1678,  13.5460\n",
      "10,  97.8347,  13.7076\n",
      "11,  97.8347,  13.6845\n",
      "12,  97.8347,  13.6573\n",
      "13,  97.8347,  13.6869\n",
      "14,  97.8347,  13.6163\n",
      "15,  97.8347,  13.6871\n",
      "16,  97.8347,  13.6285\n",
      "17,  92.3381,  12.6140\n",
      "18,  98.1678,  13.6178\n",
      "19,  97.8347,  13.7038\n",
      "20,  97.8347,  13.7317\n",
      "21,  97.8347,  13.6783\n",
      "22,  97.8347,  13.7334\n",
      "23,  97.8347,  13.6688\n",
      "24,  97.8347,  13.6912\n",
      "25,  97.8347,  13.6466\n",
      "26,  97.8347,  13.7157\n",
      "27,  97.8347,  13.6604\n",
      "28,  97.8347,  13.7310\n",
      "29,  97.8347,  13.6359\n",
      "30,  89.6731,  12.4679\n",
      "31,  98.1678,  13.5093\n",
      "32,  97.8347,  13.5849\n",
      "33,  97.8347,  13.5858\n",
      "34,  97.8347,  13.5331\n",
      "35,  97.8347,  13.6147\n",
      "36,  97.8347,  13.5465\n",
      "37,  95.3362,  13.1271\n",
      " 0, 100.0000,  13.7811\n",
      " 1,  97.6369,  13.4270\n",
      " 2,  98.3344,  13.7272\n",
      " 3,  97.8347,  13.6645\n",
      " 4,  97.8347,  13.7031\n",
      " 5,  97.8347,  13.6392\n",
      " 6,  97.8347,  13.7076\n",
      " 7,  97.8347,  13.6287\n",
      " 8,  94.3369,  12.5184\n",
      " 9,  98.1678,  13.4914\n",
      "10,  97.8347,  13.6907\n",
      "11,  97.8347,  13.7155\n",
      "12,  97.8347,  13.6693\n",
      "13,  97.8347,  13.6962\n",
      "14,  97.8347,  13.6478\n",
      "15,  97.8347,  13.6955\n",
      "16,  97.8347,  13.6728\n",
      "17,  92.3381,  12.6493\n",
      "18,  98.1678,  13.6085\n",
      "19,  97.8347,  13.6979\n",
      "20,  97.8347,  13.6967\n",
      "21,  97.8347,  13.6561\n",
      "22,  97.8347,  13.6702\n",
      "23,  97.8347,  13.6662\n",
      "24,  97.8347,  13.6943\n",
      "25,  97.8347,  13.6490\n",
      "26,  97.8347,  13.6945\n",
      "27,  97.8347,  13.6266\n",
      "28,  97.8347,  13.7179\n",
      "29,  97.8347,  13.6774\n",
      "30,  89.6731,  12.4888\n",
      "31,  98.1678,  13.4687\n",
      "32,  97.8347,  13.5746\n",
      "33,  97.8347,  13.6287\n",
      "34,  97.8347,  13.5584\n",
      "35,  97.8347,  13.6154\n",
      "36,  97.8347,  13.5629\n",
      "37,  95.3362,  13.1121\n",
      " 0, 100.0000,  13.7656\n",
      " 1,  97.6369,  13.4301\n",
      " 2,  98.3344,  13.6824\n",
      " 3,  97.8347,  13.6530\n",
      " 4,  97.8347,  13.6845\n",
      " 5,  97.8347,  13.6552\n",
      " 6,  97.8347,  13.7229\n",
      " 7,  97.8347,  13.6399\n",
      " 8,  94.3369,  12.4888\n",
      " 9,  98.1678,  13.5224\n",
      "10,  97.8347,  13.6993\n",
      "11,  97.8347,  13.7150\n",
      "12,  97.8347,  13.6354\n",
      "13,  97.8347,  13.7269\n",
      "14,  97.8347,  13.6201\n",
      "15,  97.8347,  13.6700\n",
      "16,  97.8347,  13.6271\n",
      "17,  92.3381,  12.6441\n",
      "18,  98.1678,  13.5970\n",
      "19,  97.8347,  13.6979\n",
      "20,  97.8347,  13.7141\n",
      "21,  97.8347,  13.6578\n",
      "22,  97.8347,  13.7177\n",
      "23,  97.8347,  13.6535\n",
      "24,  97.8347,  13.7124\n",
      "25,  97.8347,  13.6583\n",
      "26,  97.8347,  13.7217\n",
      "27,  97.8347,  13.6757\n",
      "28,  97.8347,  13.6957\n",
      "29,  97.8347,  13.6621\n",
      "30,  89.6731,  12.5217\n",
      "31,  98.1678,  13.4702\n",
      "32,  97.8347,  13.5593\n",
      "33,  97.8347,  13.6194\n",
      "34,  97.8347,  13.5522\n",
      "35,  97.8347,  13.6185\n",
      "36,  97.8347,  13.5577\n",
      "37,  95.3362,  13.1357\n",
      " 0, 100.0000,  13.7935\n",
      " 1,  97.6369,  13.4294\n",
      " 2,  98.3344,  13.7091\n",
      " 3,  97.8347,  13.6731\n",
      " 4,  97.8347,  13.6845\n",
      " 5,  97.8347,  13.6614\n",
      " 6,  97.8347,  13.7138\n",
      " 7,  97.8347,  13.6297\n",
      " 8,  94.3369,  12.4855\n",
      " 9,  98.1678,  13.5775\n",
      "10,  97.8347,  13.6731\n",
      "11,  97.8347,  13.7062\n",
      "12,  97.8347,  13.6685\n",
      "13,  97.8347,  13.7112\n",
      "14,  97.8347,  13.6511\n",
      "15,  97.8347,  13.7024\n",
      "16,  97.8347,  13.7038\n",
      "17,  92.3381,  12.5976\n",
      "18,  98.1678,  13.6135\n",
      "19,  97.8347,  13.7224\n",
      "20,  97.8347,  13.7124\n",
      "21,  97.8347,  13.6416\n",
      "22,  97.8347,  13.6926\n",
      "23,  97.8347,  13.6647\n",
      "24,  97.8347,  13.7064\n",
      "25,  97.8347,  13.6518\n",
      "26,  97.8347,  13.6986\n",
      "27,  97.8347,  13.6628\n",
      "28,  97.8347,  13.6957\n",
      "29,  97.8347,  13.6685\n",
      "30,  89.6731,  12.4826\n",
      "31,  98.1678,  13.4752\n",
      "32,  97.8347,  13.5801\n",
      "33,  97.8347,  13.6254\n",
      "34,  97.8347,  13.5567\n",
      "35,  97.8347,  13.6437\n",
      "36,  97.8347,  13.5505\n",
      "37,  95.3362,  13.1140\n",
      " 0, 100.0000,  13.7618\n",
      " 1,  97.6369,  13.4277\n",
      " 2,  98.3344,  13.7119\n",
      " 3,  97.8347,  13.6290\n",
      " 4,  97.8347,  13.7055\n",
      " 5,  97.8347,  13.6356\n",
      " 6,  97.8347,  13.7246\n",
      " 7,  97.8347,  13.6406\n",
      " 8,  94.3369,  12.4841\n",
      " 9,  98.1678,  13.5303\n",
      "10,  97.8347,  13.7401\n",
      "11,  97.8347,  13.6998\n",
      "12,  97.8347,  13.6187\n",
      "13,  97.8347,  13.7107\n",
      "14,  97.8347,  13.6549\n",
      "15,  97.8347,  13.7057\n",
      "16,  97.8347,  13.6685\n",
      "17,  92.3381,  12.5911\n",
      "18,  98.1678,  13.5992\n",
      "19,  97.8347,  13.7074\n",
      "20,  97.8347,  13.7205\n",
      "21,  97.8347,  13.6619\n",
      "22,  97.8347,  13.6786\n",
      "23,  97.8347,  13.6399\n",
      "24,  97.8347,  13.6986\n",
      "25,  97.8347,  13.6266\n",
      "26,  97.8347,  13.7196\n",
      "27,  97.8347,  13.6719\n",
      "28,  97.8347,  13.7072\n",
      "29,  97.8347,  13.6502\n",
      "30,  89.6731,  12.4474\n",
      "31,  98.1678,  13.4711\n",
      "32,  97.8347,  13.5672\n",
      "33,  97.8347,  13.5980\n",
      "34,  97.8347,  13.5882\n",
      "35,  97.8347,  13.6132\n",
      "36,  97.8347,  13.5093\n",
      "37,  95.3362,  13.0911\n"
     ]
    }
   ],
   "source": [
    "net, _ = ResNet50_gating(1000)\n",
    "mapper = ResNetGatesModulesMapper(net.net, False, False)\n",
    "hyper_edge_to_active_channels = create_edge_to_channels_map(mapper, net.forward_hooks)\n",
    "\n",
    "original_cost = 76848.00\n",
    "\n",
    "channels_config = filter_mapping_from_default_resnet(resnet50(False))\n",
    "orig_resnet = custom_resnet_50(channels_config)\n",
    "orig_resnet = orig_resnet.cuda(1)\n",
    "\n",
    "# meas = []\n",
    "\n",
    "\n",
    "for _ in range(9):\n",
    "    print(\"{:2d}, {:8.4f}, {:8.4f}\".format(0, 100, time_net(orig_resnet, measurements=100, sleep_seconds=100)))\n",
    "    for i, (_,ch_num_change) in enumerate(hyper_edge_to_active_channels.items()):\n",
    "        conv_channels_dict = {}\n",
    "        ch_num_change = int(ch_num_change * 0.5)\n",
    "        for j, (hyper_edge, ch_num_keep) in enumerate(hyper_edge_to_active_channels.items()):\n",
    "            num_channels = hyper_edge_to_active_channels[hyper_edge]\n",
    "            # take only out channels of convolutions\n",
    "            num_channels = ch_num_change if i==j else ch_num_keep\n",
    "            for k, (_, s) in enumerate(hyper_edge.convs_and_sides):\n",
    "                if not s:\n",
    "                    dot_string_to_tree_dict(conv_channels_dict, hyper_edge.conv_names[k], num_channels)\n",
    "\n",
    "        custom_net = custom_resnet_50(conv_channels_dict).cuda(1)\n",
    "        new_cost, _ = custom_net.compute_flops_memory()\n",
    "        print(\"{:2d}, {:8.4f}, {:8.4f}\".format(i+1, 100*new_cost/original_cost, time_net(custom_net, measurements=100, sleep_seconds=100)))\n",
    "    \n",
    "    # measure original net as a sanity check\n",
    "#     if ((i % 10) == 0) and (i > 0):\n",
    "#         meas.append(time_net(orig_resnet, measurements=100, sleep_seconds=100))\n",
    "\n",
    "# measure original net as a sanity check   \n",
    "# meas.append(time_net(orig_resnet, measurements=100, sleep_seconds=100))\n",
    "\n",
    "# run again to double check similar timing\n",
    "# for m in meas:\n",
    "#     print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
