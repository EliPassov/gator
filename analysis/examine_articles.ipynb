{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torchvision.models.resnet import resnet50\n",
    "from torchvision.models.mobilenet import mobilenet_v2\n",
    "from torchvision.models.squeezenet import squeezenet1_0, squeezenet1_1\n",
    "from torchvision.models.shufflenetv2 import shufflenet_v2_x1_0\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'analysis':\n",
    "    os.chdir('..')\n",
    "from external_models.dcp.pruned_resnet import PrunedResnet30, PrunedResnet50, PrunedResnet70\n",
    "from models.gate_wrapped_module import compute_flop_cost_change\n",
    "from models.custom_resnet import filter_mapping_from_default_resnet, custom_resnet_50, custom_resnet_56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/victoria/Downloads/resnet50-20210116T145733Z-001/resnet50/pretrain-resnet50-ratenorm1-ratedist0.4/best.resnet50.2018-07-16-4310.pth.tar'\n",
    "aaa = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = aaa['state_dict']\n",
    "state_dict = {k[7:]:v for k,v in state_dict.items()}\n",
    "net = resnet50(pretrained=False)\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_weights_analysis(weights, prev_out=None):\n",
    "    no_kernals = (weights!=0).sum(-1).sum(-1) != 0\n",
    "#     no_kernals = weights.sum(-1).sum(-1) != 0\n",
    "#     init_filters = no_kernals.size(0), no_kernals.size(1)\n",
    "    in_non_zero = (no_kernals.sum(0) > 0).sum().item()\n",
    "    out_non_zero = (no_kernals.sum(1) > 0).sum().item()\n",
    "    if prev_out is not None:\n",
    "        in_non_zero = min(in_non_zero, prev_out)\n",
    "    init_cost = weights.numel()\n",
    "    final_cost  = in_non_zero*out_non_zero *weights.size(2) * weights.size(3)\n",
    "    return init_cost, final_cost, in_non_zero, out_non_zero\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample = 4\n",
    "\n",
    "channel_config = {}\n",
    "\n",
    "res1, res2, in_channels, out_channels  = conv_weights_analysis(net.conv1.weight.data)\n",
    "channel_config['conv1'] = out_channels\n",
    "first_conv_out = out_channels\n",
    "orig_total = res1/4 \n",
    "orig_memory = res1\n",
    "new_total = res2/4\n",
    "# print(new_total )\n",
    "new_memory = res2\n",
    "for l in range(1,5):\n",
    "    layer_config = {}\n",
    "    if l > 1:\n",
    "        downsample *= 2\n",
    "    layer = getattr(net, 'layer' + str(l))\n",
    "    res1, res2, in_channels, out_channels  = conv_weights_analysis(layer[0].downsample[0].weight.data, first_conv_out if l==1 else None)\n",
    "    orig_total += res1/(downsample**2) \n",
    "    orig_memory += res1\n",
    "    new_total += res2/(downsample**2) \n",
    "#     print('down', res2/(downsample**2),  in_channels, out_channels )\n",
    "#     print(new_total )\n",
    "    new_memory += res2\n",
    "    for i in range(len(layer)):\n",
    "        block_config = {}\n",
    "        if i==0:\n",
    "            block_config['downsample'] = out_channels\n",
    "        for j in range(1,4):\n",
    "            prev_out = None\n",
    "            if j==1 and l==1 and i==0:\n",
    "                prev_out = first_conv_out\n",
    "            elif j>1:\n",
    "                prev_out = out_channels\n",
    "            \n",
    "            res1, res2, in_channels, out_channels  = conv_weights_analysis(getattr(layer[i],'conv'+str(j)).weight.data, prev_out)\n",
    "#             if j == 3:\n",
    "#                 out_channels = layer[i].conv3.weight.size(0)\n",
    "            block_config['conv'+str(j)] = out_channels\n",
    "            orig_total += res1/(downsample**2) \n",
    "            orig_memory += res1\n",
    "            new_total += res2/(downsample**2) \n",
    "#             print('conv'+str(j), res2/(downsample**2), in_channels, out_channels )\n",
    "#             print(new_total )\n",
    "            new_memory += res2\n",
    "        layer_config[str(i)] = block_config\n",
    "    channel_config['layer'+str(l)] = layer_config\n",
    "fc_size = net.fc.in_features * net.fc.out_features\n",
    "fc_flops = fc_size / (224**2)\n",
    "\n",
    "orig_total += fc_flops\n",
    "orig_memory += fc_size\n",
    "new_total += fc_flops\n",
    "new_memory += fc_size\n",
    "\n",
    "# print (fc_flops)\n",
    "# print(new_total)\n",
    "\n",
    "print(orig_total, new_total, 1-new_total/orig_total, orig_total/new_total, orig_memory, new_memory)\n",
    "print(channel_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_from_config =custom_resnet_50(channel_config)\n",
    "print(net_from_config.compute_flops_memory())\n",
    "# res = net_from_config(torch.randn(1,3,64,64))\n",
    "# res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_net(net, batch_size=8, run_times=1, measurements=100, lower_limit=0, upper_limit=500000, sleep_seconds=150, return_times=False):\n",
    "    net.eval()\n",
    "    total_times=[]\n",
    "    for r in range(run_times):\n",
    "        if r > 0:\n",
    "            sleep(sleep_seconds)\n",
    "        sample = torch.rand((batch_size,3,224,224)).cuda(1)\n",
    "        times = []\n",
    "        for i in range(measurements):\n",
    "            t = time()\n",
    "            res = net(sample)\n",
    "            aa = res[-1,-1].item()\n",
    "            times.append(time()-t)\n",
    "        times = np.array(times)\n",
    "        times = 1000 * times\n",
    "#         times.sort()\n",
    "#         times = times[lower_limit:upper_limit]\n",
    "        total_times.append(times)\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    total_times=np.array(total_times)\n",
    "    \n",
    "    if return_times:\n",
    "        return total_times\n",
    "    else:\n",
    "        return(total_times.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_from_config = net_from_config.cuda(1)\n",
    "time_net(net_from_config, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_cost(m, down):\n",
    "    assert isinstance(m, torch.nn.Conv2d)\n",
    "    res = m.in_channels * m.out_channels * m.kernel_size[0] * m.kernel_size[1]\n",
    "    return res / (m.groups * down**2), res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(size=(8,10,5,5))\n",
    "y = torch.Tensor(size=(8,6,5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unmatched_channels_addition(x, y):\n",
    "    y_new = torch.cat([y, torch.zeros((y.size(0), x.size(1)-y.size(1), y.size(2), y.size(3)), device=y.device)],1)\n",
    "    return x + y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros((y.size(0), x.size(1)-y.size(1), y.size(2), y.size(3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_channels_addition(x,y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob =mobilenet_v2(pretrained=False)\n",
    "downsample = 1\n",
    "flops = 0\n",
    "memory = 0\n",
    "for m in mob.modules():\n",
    "    if not isinstance(m, torch.nn.Conv2d):\n",
    "        if isinstance(m, torch.nn.Linear):\n",
    "            flops += m.in_features * m.out_features / (224**2)\n",
    "            memory +=m.in_features * m.out_features\n",
    "    else:\n",
    "        if m.stride[0] == 2:\n",
    "            downsample = 2 * downsample\n",
    "        flops += m.in_channels* m.out_channels* m.kernel_size[0]* m.kernel_size[1] / (m.groups * downsample**2)\n",
    "        memory += m.in_channels* m.out_channels* m.kernel_size[0]* m.kernel_size[1]\n",
    "print(flops, memory, downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "76848 / 5994.385204081633 , 76848 / 5968.875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5994.385204081633 *224 *224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_0 = False\n",
    "\n",
    "sq = squeezenet1_0(False) if sq_0 else squeezenet1_1(False)\n",
    "\n",
    "downsample = 4\n",
    "\n",
    "flops, memory = get_conv_cost(sq.features[0], 2)\n",
    "\n",
    "for i in range(3,13):\n",
    "    if i in ([6,11] if sq_0 else [5,8]):\n",
    "        downsample *= 2\n",
    "    else:\n",
    "        for m in sq.features[i].modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                if m.stride[0] == 2:\n",
    "                    downsample = 2 * downsample\n",
    "                f, m = get_conv_cost(m, downsample)\n",
    "                flops += f\n",
    "                memory += m\n",
    "f, m = get_conv_cost(sq.classifier[1], downsample)\n",
    "flops += f\n",
    "memory += m     \n",
    "\n",
    "print(flops, memory, downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7720.0*224**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/victoria/d/Training/Eli/resnet50_pre_0_995_w_0_25_gm_0_2_w_0_5_w_1_w_2_custom_timing/net_e_140_simple'\n",
    "state_dict = torch.load(path)\n",
    "net = custom_resnet_50(state_dict['channels_config'], 1000)\n",
    "net.load_state_dict({k[7:]:v for k,v in state_dict['state_dict'].items()})\n",
    "print(*net.compute_flops_memory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*net.compute_flops_memory(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PrunedResnet70()\n",
    "print(*net.compute_flops_memory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/eli/Eli/Training/Cifar10/ResNet56_long/resnet56_w_0_25_w_5_w_1_w_2_w_4_w_8_w16/net_e_900'\n",
    "\n",
    "state_dict = torch.load(path)\n",
    "net = custom_resnet_56(state_dict['channels_config'], 10)\n",
    "net.load_state_dict({k[7:]:v for k,v in state_dict['state_dict'].items()})\n",
    "print(*net.compute_flops_memory())\n",
    "len(net.layer1),len(net.layer2), len(net.layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.layer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## channel pruning article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "config_path ='./analysis/channel_pruning_article_resnet50_config.txt'\n",
    "with open(config_path, 'r') as f:\n",
    "    channels_config = json.loads(f.read().replace('\\n', '').replace(\"'\", '\"'))\n",
    "net = custom_resnet_50(channels_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compute_flops_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "aa = torch.load('/home/eli/Eli/Training/Cifar10/ResNet56_long/resnet56_120_180_240/net_e_240')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa['state_dict']['module.fc.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for k, v in aa['state_dict'].items():\n",
    "    if 'conv' in k:\n",
    "        print(k, '\\t',v.shape)\n",
    "        sum += v.size(0)*v.size(1)* v.size(2)*v.size(3)\n",
    "sum += 64*10 #+ 40*3*16\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
