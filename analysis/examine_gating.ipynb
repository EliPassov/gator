{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# change to root folder\n",
    "if os.path.basename(os.getcwd()) == 'analysis':\n",
    "    os.chdir('..')\n",
    "    \n",
    "from time import time\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.vgg_fully_convolutional import *\n",
    "\n",
    "from data.dataset_factory import cifar_transform_test\n",
    "from data.dataset import CIFARDataset\n",
    "from eval import GenericEvaluator\n",
    "from utils.net_utils import load_net, NetWithResult\n",
    "from utils.run_arg_parser import parse_net_args_inner, NET_LOAD_TYPE\n",
    "from utils.forward_hooks import OutputHook\n",
    "from models.net_auxiliary_extension import NetWithAuxiliaryOutputs\n",
    "from models.gated_grouped_conv import create_target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = resnet18(True)\n",
    "net_name = 'VGG16BnDropV2_GatedHardSimple'\n",
    "weight_path = '/home/eli/Eli/Training/Cifar10/VGG16DropV2/VGG16BnDropV2_trained_gating_hard_simple_l1_static_0_000005_no_decay_sum_init_4_T_inverse_mult_10000_optimizer_softmax_schedule_200/net_backup.pt'\n",
    "load_type = NET_LOAD_TYPE.Cifar10\n",
    "net = load_net(weight_path, parse_net_args_inner(load_type, net_name, 10, False), load_type='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_dataset = CIFARDataset('/home/eli/Data/Cifar10/cifar-10-batches-py', cifar_transform_test, False, 10)\n",
    "cifar_dataloader = DataLoader(cifar_dataset, shuffle=True, batch_size=32, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_blocks = [m for m in net.modules() if isinstance(m, ConvBlock)]\n",
    "gate_outputs = [c.gate.gumble for c in conv_blocks if c.gated]\n",
    "hooks = [OutputHook(m) for m in gate_outputs]\n",
    "wrapped_net = NetWithAuxiliaryOutputs(net, hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 20\n",
    "current_batch = 0\n",
    "features_usage = []\n",
    "\n",
    "nested_list =[]\n",
    "features_usage = []\n",
    "\n",
    "for i in range(len(hooks)):\n",
    "    features_usage.append(nested_list[:])\n",
    "    for j in range(10):\n",
    "        features_usage[-1].append(nested_list[:])\n",
    "\n",
    "for b, (_, data, targets) in enumerate(cifar_dataloader):\n",
    "    if current_batch >= num_batches:\n",
    "        break\n",
    "    _, hooks_out = wrapped_net(data)\n",
    "#     diff_mask = create_target_mask(targets)\n",
    "#     same_mask = (target_mask == 0) - torch.eye(mask.size(0))\n",
    "    for i, hook_out in enumerate(hooks_out):\n",
    "        for j in range(data.size(0)):\n",
    "            features_usage[i][targets[j]].append(hook_out[j].detach().numpy())\n",
    "    current_batch += 1\n",
    "\n",
    "for i in range(len(hooks_out)):\n",
    "    for j in range(10):\n",
    "        features_usage[i][j] = np.array(features_usage[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_split = False\n",
    "if class_split:\n",
    "    for i in range(len(hooks_out)):\n",
    "        plt.figure(i, figsize=(20,12))\n",
    "        for j in range(10):\n",
    "            plt.scatter(np.linspace(1,features_usage[i][j].shape[1],features_usage[i][j].shape[1]), features_usage[i][j].sum(0)/features_usage[i][j].shape[0])\n",
    "else:\n",
    "    for i in range(len(hooks_out)):\n",
    "        combined = np.concatenate(features_usage[i],0)\n",
    "        plt.figure(i, figsize=(10,6))\n",
    "        plt.scatter(np.linspace(1,combined.shape[1],combined.shape[1]), combined.mean(0))\n",
    "#         print(((((np.absolute(combined.mean(0) - 0.5) - 0.45) > 0).sum())/combined.shape[1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels_to_prune(features_usage, threshold=0.5):\n",
    "    features_usage = [np.concatenate(features_usage_layer) for features_usage_layer in features_usage]\n",
    "    features_to_prune = [[]] # first layer not gated\n",
    "    for i, features_usage_layer in enumerate(features_usage):\n",
    "        multiplier = 1\n",
    "        if hasattr(conv_blocks[i], 'dropout') and conv_blocks[i].dropout is not None:\n",
    "            multiplier = (1-conv_blocks[i].dropout.p)\n",
    "        features_to_prune.append(np.where(features_usage_layer.mean(0) < threshold * multiplier)[0].tolist())\n",
    "    return features_to_prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_to_prune = get_channels_to_prune(features_usage, 0.7)\n",
    "print('ch\\tpruned\\tpercent\\tcost')\n",
    "for i, c in enumerate(channels_to_prune):\n",
    "    print(conv_blocks[i].conv.in_channels, '\\t', len(c), '\\t', '{:5.2f}'.format(100* len(c)/conv_blocks[i].conv.in_channels), '\\t', conv_blocks[i].in_channel_flop_cost_prune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval1 = GenericEvaluator(NetWithResult(net), cifar_dataloader).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_no_gates = net.get_net_without_gating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pruned_net(net, channels_to_prune):\n",
    "    i = 0\n",
    "    prev_conv_module = None\n",
    "    flops_cost = 0\n",
    "    total_memory = 0\n",
    "    saved_memory = 0\n",
    "    # if we are using pruning on first module, we will get an error\n",
    "    conv_blocks = [conv_module for conv_module in net.modules() if isinstance(conv_module, ConvBlock)]\n",
    "    for conv_module in conv_blocks:\n",
    "        total_memory += conv_module.conv.in_channels * conv_module.conv.out_channels\n",
    "        saved_memory += len(channels_to_prune[i]) * conv_module.conv.out_channels\n",
    "        flops_cost += conv_module.in_channel_flop_cost * (conv_module.conv.in_channels - len(channels_to_prune[i]))\n",
    "        for ind in channels_to_prune[i]:\n",
    "            conv_module.nullify_input_channel(ind)\n",
    "            prev_conv_module.nullify_output_channel(ind)\n",
    "#             flops_saved += conv_module.in_channel_flop_cost_prune\n",
    "        prev_conv_module = conv_module\n",
    "        i += 1\n",
    "    flops_saved = net.total_pixel_flop_cost - flops_cost\n",
    "    print('Saved {} flops per pixel from a total of {} ({:5.2f}%)'.format(flops_saved, net.total_pixel_flop_cost, 100 * flops_saved / net.total_pixel_flop_cost))\n",
    "    print('Compression ratio: {:5.2f}'.format(total_memory/(total_memory-saved_memory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval2 = GenericEvaluator(NetWithResult(net_no_gates), cifar_dataloader).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pruned_net(net_no_gates, channels_to_prune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval3 = GenericEvaluator(NetWithResult(net_no_gates), cifar_dataloader).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
